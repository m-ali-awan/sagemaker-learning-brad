{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa463eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9bfbd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch_smmodelparallel_mnist.ipynb  utils\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80255c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sagemaker-experiments\n",
      "  Downloading sagemaker_experiments-0.1.33-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 759 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.16.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sagemaker-experiments) (1.17.87)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.87 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from boto3>=1.16.27->sagemaker-experiments) (1.20.87)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.87->boto3>=1.16.27->sagemaker-experiments) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.87->boto3>=1.16.27->sagemaker-experiments) (1.26.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.87->boto3>=1.16.27->sagemaker-experiments) (1.15.0)\n",
      "Installing collected packages: sagemaker-experiments\n",
      "Successfully installed sagemaker-experiments-0.1.33\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker-experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae6aab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role:arn:aws:iam::886035371869:role/torchserve-workshop-SageMakerAPIExecutionRole\n",
      "CPU times: user 41.6 ms, sys: 8.02 ms, total: 49.7 ms\n",
      "Wall time: 97.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "role = (\n",
    "    get_execution_role()\n",
    ")  # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "print(f\"SageMaker Execution Role:{role}\")\n",
    "\n",
    "session = boto3.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b0a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session(boto_session=session)\n",
    "mpioptions = \"-verbose -x orte_base_help_aggregate=0 \"\n",
    "\n",
    "all_experiment_names = [exp.experiment_name for exp in Experiment.list()]\n",
    "\n",
    "# choose an experiment name (only need to create it once)\n",
    "experiment_name = \"SM-MP-DEMO\"\n",
    "\n",
    "# Load the experiment if it exists, otherwise create\n",
    "if experiment_name not in all_experiment_names:\n",
    "    customer_churn_experiment = Experiment.create(\n",
    "        experiment_name=experiment_name, sagemaker_boto_client=boto3.client(\"sagemaker\")\n",
    "    )\n",
    "else:\n",
    "    customer_churn_experiment = Experiment.load(\n",
    "        experiment_name=experiment_name, sagemaker_boto_client=boto3.client(\"sagemaker\")\n",
    "    )\n",
    "\n",
    "# Create a trial for the current run\n",
    "trial = Trial.create(\n",
    "    trial_name=\"SMD-MP-demo-{}\".format(strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())),\n",
    "    experiment_name=customer_churn_experiment.experiment_name,\n",
    "    sagemaker_boto_client=boto3.client(\"sagemaker\"),\n",
    ")\n",
    "\n",
    "\n",
    "smd_mp_estimator = PyTorch(\n",
    "    entry_point=\"pt_mnist.py\",  # Pick your train script\n",
    "    source_dir=\"utils\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.p3.16xlarge\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py36\",\n",
    "    instance_count=1,\n",
    "    distribution={\n",
    "        \"smdistributed\": {\n",
    "            \"modelparallel\": {\n",
    "                \"enabled\": True,\n",
    "                \"parameters\": {\n",
    "                    \"microbatches\": 4,\n",
    "                    \"placement_strategy\": \"spread\",\n",
    "                    \"pipeline\": \"interleaved\",\n",
    "                    \"optimize\": \"speed\",\n",
    "                    \"partitions\": 2,\n",
    "                    \"ddp\": True,\n",
    "                },\n",
    "            }\n",
    "        },\n",
    "        \"mpi\": {\n",
    "            \"enabled\": True,\n",
    "            \"processes_per_host\": 2,  # Pick your processes_per_host\n",
    "            \"custom_mpi_options\": mpioptions,\n",
    "        },\n",
    "    },\n",
    "    base_job_name=\"SMD-MP-demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cecc91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: SMD-MP-demo-2021-06-14-14-05-37-359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-14 14:05:37 Starting - Starting the training job...\n",
      "2021-06-14 14:05:41 Starting - Launching requested ML instancesProfilerReport-1623679537: InProgress\n",
      ".........\n",
      "2021-06-14 14:07:28 Starting - Preparing the instances for training.........\n",
      "2021-06-14 14:09:08 Downloading - Downloading input data...\n",
      "2021-06-14 14:09:28 Training - Downloading the training image..............\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:46,900 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:46,979 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:46,988 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,593 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,593 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,596 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,596 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1'] Hosts: ['algo-1:2'] process_per_hosts: 2 num_processes: 2\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,600 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2021-06-14 14:11:47,679 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 2,\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-verbose -x orte_base_help_aggregate=0 \",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_instance_type\": \"ml.p3.16xlarge\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"mp_parameters\": {\n",
      "            \"microbatches\": 4,\n",
      "            \"placement_strategy\": \"spread\",\n",
      "            \"pipeline\": \"interleaved\",\n",
      "            \"optimize\": \"speed\",\n",
      "            \"partitions\": 2,\n",
      "            \"ddp\": true\n",
      "        }\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"SMD-MP-demo-2021-06-14-14-05-37-359\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-886035371869/SMD-MP-demo-2021-06-14-14-05-37-359/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"pt_mnist\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"pt_mnist.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"mp_parameters\":{\"ddp\":true,\"microbatches\":4,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"spread\"}}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=pt_mnist.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=pt_mnist\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-886035371869/SMD-MP-demo-2021-06-14-14-05-37-359/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p3.16xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-verbose -x orte_base_help_aggregate=0 \",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":2},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"mp_parameters\":{\"ddp\":true,\"microbatches\":4,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"spread\"}},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"SMD-MP-demo-2021-06-14-14-05-37-359\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-886035371869/SMD-MP-demo-2021-06-14-14-05-37-359/source/sourcedir.tar.gz\",\"module_name\":\"pt_mnist\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"pt_mnist.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--mp_parameters\",\"ddp=True,microbatches=4,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=spread\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_MP_PARAMETERS={\"ddp\":true,\"microbatches\":4,\"optimize\":\"speed\",\"partitions\":2,\"pipeline\":\"interleaved\",\"placement_strategy\":\"spread\"}\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:2 -np 2 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.6/site-packages/gethostname.cpython-36m-x86_64-linux-gnu.so -verbose -x orte_base_help_aggregate=0 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_HP_MP_PARAMETERS -x PYTHONPATH /opt/conda/bin/python3.6 -m mpi4py pt_mnist.py --mp_parameters ddp=True,microbatches=4,optimize=speed,partitions=2,pipeline=interleaved,placement_strategy=spread\n",
      "\n",
      "\n",
      " Data for JOB [41213,1] offset 0 Total slots allocated 2\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: algo-1#011Num slots: 2#011Max slots: 0#011Num procs: 2\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41213,1] App: 0 Process rank: 1 Bound: N/A\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-06-14 14:11:51.894: I smdistributed/modelparallel/torch/state_mod.py:114] [1] Finished initializing torch distributed process groups. mp_rank: 1, dp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-06-14 14:11:51.904: I smdistributed/modelparallel/torch/state_mod.py:114] [0] Finished initializing torch distributed process groups. mp_rank: 0, dp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\u001b[0m\n",
      "\n",
      "2021-06-14 14:12:09 Training - Training image download completed. Training in progress.\n",
      "2021-06-14 14:47:49 Stopping - Stopping the training job\n",
      "2021-06-14 14:49:50 Uploading - Uploading generated training model\n",
      "2021-06-14 14:49:54 Stopped - Training job stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 2457\n",
      "Billable seconds: 2457\n"
     ]
    }
   ],
   "source": [
    "smd_mp_estimator.fit(\n",
    "    experiment_config={\n",
    "        \"ExperimentName\": customer_churn_experiment.experiment_name,\n",
    "        \"TrialName\": trial.trial_name,\n",
    "        \"TrialComponentDisplayName\": \"Training\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c119f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_mp_estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6a0b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "smd_mp_estimator.model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1d31e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
